import numpy as npimport good_bad as gbimport headlines as hlimport random_indexing as rifrom datetime import datetimeimport matplotlib.pyplot as pltfrom tsne import tsnenow = datetime.now().strftime("%Y-%m-%d %H:%M:%S")# get relevant news headlines and wordsnews = hl.get_articles('2016','Volkswagen', pages=100)headlines = hl.get_headlines_noStopWords(news, display=0)key_words = hl.generate_unique_key_words_list(headlines)print key_wordsnum_headlines = len(headlines)num_words = len(key_words)# save data usedhl.save_obj(news, "news_" + now)hl.save_obj(headlines, "headlines_" + now)hl.save_obj(key_words, "key_words_" + now)# load stock datadata_path = '/Users/212473475/git/ri_headlines/stock_data/'data_fn = 'vow3.de_from_010115to022117_daily.csv'data = gb.load_data(data_path, data_fn)# generate random indexing vectorsk = 500n = 1000headline_vectors = ri.generate_vectors(headlines, k=k, n=n)word_vectors = ri.generate_word_vectors(key_words, headlines, headline_vectors, k=k, n=n)# normalize headline and word vectorsheadline_vectors_norm = np.linalg.norm(headline_vectors, axis=0)word_vectors_norm = np.linalg.norm(word_vectors, axis=0)headline_vectors_normed = np.divide(headline_vectors, headline_vectors_norm)word_vectors_normed = np.divide(word_vectors, word_vectors_norm)# calculate good and bad vectors based on positive negative stock pricegood_vector = np.zeros(n)bad_vector = np.zeros(n)for i in np.arange(num_headlines):    headline, date = headlines[i]    value = gb.pos_or_neg(data, datetime.strptime(date, '%Y-%m-%d'))    if value == 1:        good_vector += headline_vectors_normed[i,:]    elif value == -1:        bad_vector += headline_vectors_normed[i, :]# normalize good and bad vectorsgood_vector /= np.linalg.norm(good_vector)bad_vector /= np.linalg.norm(bad_vector)# tiled word vec is num_headlines x n#tiled_word_vec = np.tile(word_vectors[i,:], (2, 1))# calculate and sort goodness of words# return top 10word_goodness = np.abs(np.dot(word_vectors_normed, good_vector))sorted_word_goodness_args = np.argsort(word_goodness)print "~~~~~~~~~~~~"print " good words "for i in xrange(10):    print key_words[sorted_word_goodness_args[i]], word_goodness[sorted_word_goodness_args[i]]# calculate and sort badness of words# return top 10word_badness = np.abs(np.dot(word_vectors_normed, bad_vector))sorted_word_badness_args = np.argsort(word_badness)print "~~~~~~~~~~~~"print " bad words "for i in xrange(10):    print key_words[sorted_word_badness_args[i]], word_badness[sorted_word_badness_args[i]]def new_headline_test(new_headline="Volkswagen Said to Be Close to Settling Justice Inquiry Into Emissions"):    new_hl = new_headline    new_hl_v = np.zeros(n)    key_words_searchable = []    for word, _ in key_words:        key_words_searchable.append(word)    for word in new_hl:        if word in key_words_searchable:            new_hl_v += word_vectors[key_words_searchable.index(word)]    new_hl_v /= np.linalg.norm(new_hl_v)    new_hl_v[np.isnan(new_hl_v)]=0    goodness = new_hl_v.dot(good_vector)    badness = new_hl_v.dot(bad_vector)    # returns if the headline is a bad headline    return goodness > badness new_headline_test()# test good/bad on recent newstest_news = hl.get_articles('2017','Volkswagen', pages=10)headlines = hl.get_headlines_noStopWords(test_news, display=0)correct = 0total = 0for i in np.arange(len(headlines)):    total += 1    headline, date = headlines[i]    badness = new_headline_test(new_headline=headline)    value = gb.pos_or_neg(data, datetime.strptime(date, '%Y-%m-%d'))    if value == badness:        correct += 1print correct/float(total)y_1 = tsne(word_vectors_normed[sorted_word_goodness_args[:10]])y_2 = tsne(word_vectors_normed[sorted_word_badness_args[:10]])y_1 = np.array(y_1)y_2 = np.array(y_2)y = np.concatenate(y_1, y_2)plt.scatter(y[:,0], y[:,1])gb_idx = np.concatenate(sorted_word_goodness_args[:10],sorted_word_badness_args[:10])for label, x, y in zip(np.array(key_words_searchable)[gb_idx], y[:,0], y[:,1]):    plt.annotate(label,xy = (x, y), xytext=(-20,20),    textcoords='offset points',    ha='right',    va='bottom',    bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),    arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))plt.show()